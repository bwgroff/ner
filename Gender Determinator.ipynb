{
 "metadata": {
  "name": "",
  "signature": "sha256:16455981f8a15da2ac2688a2ed1e61b105b89f4f8ee7664695273f700c7eaef1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "import string\n",
      "import nltk\n",
      "from itertools import izip_longest\n",
      "\n",
      "# sample sentence\n",
      "s = \"It's shared by the ``All Things Considered'' hosts, Dr. Robert Siegel and Linda Wertheimer, and the hourly news reader Ann Taylor as, year by year, day by day, they wend their way through the vagaries of events and time.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Name Extraction Components"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = string.maketrans(\"\",\"\")\n",
      "def no_punc(w):\n",
      "    # N.B.: Will cause trouble with names containing punctuation\n",
      "    return w.translate(table, string.punctuation)\n",
      "\n",
      "no_punc(\"':;N[ame,\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "'Name'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def long_names(words, i):\n",
      "    # This finds names longer than a single word and reports them back and how many skips\n",
      "    # are needed to get to the proper next position.\n",
      "    # N.B.: Middle initials not supported\n",
      "    words.append(\" \")\n",
      "    skip_count = 0\n",
      "    full_name = [words[i]]\n",
      "    while words[i + skip_count][-1] not in string.punctuation and words[i + skip_count + 1].istitle():\n",
      "        skip_count += 1\n",
      "    return \" \".join([no_punc(w) for w in words[i:i+skip_count+1]]), skip_count\n",
      "\n",
      "long_names(\"Hello there Bradley Williams Groff, Data Scientist\".split(), 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "('Bradley Williams Groff', 2)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a pretty simple method to identify names. If there is a match in a dataset and the word is the proper part of speech it is considered an eligible name. This is an obvious place to get better results by substituting a more sophisticated method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_name(word, namebank, i, tags):\n",
      "    # Checks whether the word in question is a part of speech which could possibly be a name\n",
      "    # and if it matches a known name.\n",
      "    return word in namebank and tags[i][1].startswith(\"NN\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def possible_names(s, namebank):\n",
      "    # Extracts names based on matching a title or matching against a table of names.\n",
      "    # Requires proper capitalization. Names which are not fully capitalized will not work properly.\n",
      "    # e.g Pierre de la Harpe ==> Pierre vs. Pierre De La Harpe ==> Pierre De La Harpe\n",
      "    # Also, Dr. Pepper.\n",
      "    words = nltk.word_tokenize(s)\n",
      "    names = []\n",
      "    skip_count = 0\n",
      "    pos_tags = nltk.pos_tag(nltk.word_tokenize(s))\n",
      "    for i, word in enumerate(words):\n",
      "        if word[0] == word[0].lower() or skip_count > 0:\n",
      "            skip_count -= 1\n",
      "            continue\n",
      "        else:\n",
      "            name = None\n",
      "            if word in [\"Ms.\", \"Mrs.\", \"Mr.\", \"Dr.\"]:\n",
      "                name, skip_count = long_names(words, i + 1)\n",
      "                skip_count += 1\n",
      "                name = word + \" \" + name\n",
      "            else:\n",
      "                clean_w = no_punc(word)\n",
      "                if is_name(clean_w, namebank, i, pos_tags):\n",
      "                    name, skip_count = long_names(words,i)\n",
      "            if name: names.append([name, i])\n",
      "    return names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Other possible Name Extraction techniques:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The possible_names function isn't ideal but because the name extraction and gender identification components are factored it is easy to substitute other methods. for instance, we could easily use the NER module of Stanford's CoreNLP or the built-in model in NLTK. I refrained from using these approaches because I didn't think solutions of this form would be acceptable:\n",
      "\n",
      "    from SuperMagic import NamedEntityMagic, GenderMagic\n",
      "    \n",
      "    def solution(sentence):\n",
      "        return GenderMagic(NamedEntityMagic(sentence))\n",
      "        \n",
      "Here's a quick implementation of the NLTK model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chunker(s):\n",
      "    return nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(s)), binary=False)\n",
      "\n",
      "def chunk_names(s):\n",
      "    nertree = chunker(s)\n",
      "    names = [\" \".join([y[0] for y in x.leaves()]) for x in nertree if type(x)==nltk.tree.Tree and x.node==\"PERSON\"]\n",
      "    return names\n",
      "\n",
      "# print chunker(s)\n",
      "print chunk_names(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Robert Siegel', 'Linda Wertheimer', 'Ann Taylor']\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Gender Identification Components"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_namebank():\n",
      "    # Loads census data with gender splits for each name (top 90% of names)\n",
      "    names_male = open(\"dist.male.first\")\n",
      "    names_female = open(\"dist.female.first\")\n",
      "    names_dict = defaultdict(lambda: [0, 0])\n",
      "    \n",
      "    next_line = names_male.readline()\n",
      "    while next_line:\n",
      "        split_line = next_line.split()\n",
      "        names_dict[split_line[0].title()][0] += float(split_line[1])\n",
      "        next_line = next(names_male, None)\n",
      "        \n",
      "    next_line = names_female.readline()\n",
      "    while next_line:\n",
      "        split_line = next_line.split()\n",
      "        names_dict[split_line[0].title()][1] += float(split_line[1])\n",
      "        next_line = next(names_female, None)\n",
      "        \n",
      "    name_freqs = defaultdict(lambda: 0.49)\n",
      "    for key in names_dict.keys():\n",
      "        name_freqs[key] = names_dict[key][0] / (names_dict[key][0] + names_dict[key][1])\n",
      "    return name_freqs, names_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gender_by_context(i, words, namebank):\n",
      "    # This seeks outward from the target word until it finds a gender indicating word and reports that gender back.\n",
      "    # Looks for tiebreakers.\n",
      "    # Will have trouble with Drs. with 2 first names e.g. Dr. William Ashley will be guessed as either\n",
      "    # male or female depending on whether it is written Dr. William Ashley or Dr. Ashley\n",
      "    if words[i] == \"Dr.\" and words[i+1] in namebank.keys():\n",
      "        return namebank[words[i+1]]\n",
      "    gender_indicators = defaultdict(int)\n",
      "    gender_indicators.update({\"his\": 1, \"he\": 1, \"her\": -1, \"hers\": -1, \"she\": -1})\n",
      "    right = left = 0\n",
      "    bounds = [-1 * i, len(words) - i - 1]\n",
      "    gender = 0\n",
      "    while (left > bounds[0] or right < bounds[1]) and gender == 0:\n",
      "        left -= 1\n",
      "        right += 1\n",
      "        if left >= bounds[0]:\n",
      "            gender += gender_indicators[words[i + left]]\n",
      "        if right <= bounds[1]:\n",
      "            gender += gender_indicators[words[i + right]]\n",
      "    return 1 / (1 + 2.0**(-2.0 * gender))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gender_by_title(title, i, words):\n",
      "    # Chooses gender given title information\n",
      "    if title == \"Ms.\" or title == \"Mrs.\":\n",
      "        if words[i + 1] == \"Doubtfire\":\n",
      "            gender_odds = 1\n",
      "        else:\n",
      "            gender_odds = 0\n",
      "    elif title == \"Mr.\":\n",
      "        gender_odds = 1\n",
      "    return gender_odds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gender_by_name(name, namebank):\n",
      "    # Simply checks against the loaded data. Could have been\n",
      "    # executed as an expression but I pulled it out for consistency\n",
      "    # with the other gender_by_* methods.\n",
      "    return namebank[name[0].split()[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prob2gender(prob):\n",
      "    if prob > 0.5:\n",
      "        return \"MALE\"\n",
      "    else:\n",
      "        return \"FEMALE\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gender_guess(s, namebank, verbose = False):\n",
      "    # Uses a very basic title or name lookup.\n",
      "    names = possible_names(s, namebank)\n",
      "    genders = []\n",
      "    for name in names:\n",
      "        if name[0][:4] in [\"Ms. \", \"Mrs.\", \"Mr. \"]:\n",
      "            prob = gender_by_title(name[0][:4].split()[0], name[1], nltk.word_tokenize(s))\n",
      "        elif name[0][:3] == \"Dr.\":\n",
      "            prob = gender_by_context(name[1], nltk.word_tokenize(s), namebank)\n",
      "        else:\n",
      "            prob = gender_by_name(name, namebank)\n",
      "        genders.append({\"name\": name[0], \"prob\": prob, \"gender\": prob2gender(prob)}) \n",
      "\n",
      "    if verbose:\n",
      "        for pair in genders:\n",
      "            print \"Name:  {0}\".format(pair[\"name\"]).ljust(50) + \"Male Odds:  {0}\".format(pair[\"prob\"])\n",
      "    return genders"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "namebank, relative_namebank = build_namebank()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I was able to find some NER benchmark datasets but nothing specifically about gender. To evaluate this method I had to make my own.\n",
      "\n",
      "I hand-tagged 46 sentences from the IEER dataset, each of which contained at least one named reference to a person. Those references were tagged as either ISMALE or ISFEMALE. Due to the nature of the writing, some male references were not presented with sufficient information to classify gender, e.g. a reference to \"Edwards\" without any other gender indicating words like pronouns. Those occurences are given the tag ISMALE_NO_ID."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sentences = open(\"testdata.txt\").readlines()\n",
      "unlabeled_sents = open(\"unlabeled.txt\").readlines()\n",
      "\n",
      "for i in range(46):\n",
      "    actual = [[x.split(\"IS\")[0], x.split(\"IS\")[1].split()[0]] for x in test_sentences[i].split(\"<\")[1:]]\n",
      "    predicted = [[x[\"name\"], x[\"gender\"]] for x in gender_guess(unlabeled_sents[i], namebank)]\n",
      "    to_print = list(izip_longest(actual, predicted, fillvalue=''))\n",
      "    print \"Actual:\".ljust(50) + \"Predicted:\"\n",
      "    for line in to_print:\n",
      "        print \" \" * 2 + str(line[0]).ljust(50) + str(line[1])\n",
      "#     print (\"Actual: \" + str(actual)).ljust(70) + \"  Predicted: \" + str(predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Actual:                                           Predicted:\n",
        "  [' Bob Edwards ', 'MALE']                         ['Bob Edwards', 'MALE']\n",
        "Actual:                                           Predicted:\n",
        "  [\" Edwards' \", 'MALE_NO_ID']                      \n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Edwards ', 'MALE_NO_ID']                       \n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Robert Siegel ', 'MALE']                       ['Robert Siegel', 'MALE']\n",
        "  [' Linda Wertheimer ', 'FEMALE,']                 ['Linda Wertheimer', 'FEMALE']\n",
        "  [' Ann Taylor ', 'FEMALE']                        ['Ann Taylor', 'FEMALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Edwards ', 'MALE_NO_ID,']                      \n",
        "Actual:                                           Predicted:\n",
        "  [' Edwards ', 'MALE']                             \n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [\" Edwards' \", 'MALE_NO_ID']                      \n",
        "Actual:                                           Predicted:\n",
        "  [' Siegel ', 'MALE_NO_ID,']                       ['Ms. Wertheimer', 'FEMALE']\n",
        "  [' Ms. Wertheimer ', 'FEMALE']                    ['Ms. Taylor', 'FEMALE']\n",
        "  [' Ms. Taylor ', 'FEMALE.']                       \n",
        "Actual:                                           Predicted:\n",
        "  [\" Edwards' \", 'MALE_NO_ID']                      \n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Bill Clinton ', 'MALE']                        ['Bill Clinton', 'MALE']\n",
        "  [' Siegel ', 'MALE_NO_ID']                        ['Ms. Wertheimer', 'FEMALE']\n",
        "  [' Ms. Wertheimer ', 'FEMALE']                    \n",
        "Actual:                                           Predicted:\n",
        "  [' Mara Liasson ', 'FEMALE,']                     ['Mara Liasson', 'FEMALE']\n",
        "  [' Nina Totenberg ', 'FEMALE,']                   ['Nina Totenberg', 'FEMALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Siegel ', 'MALE_NO_ID']                        ['Ms. Wertheimer', 'FEMALE']\n",
        "  [' Ms. Wertheimer ', 'FEMALE']                    \n",
        "Actual:                                           Predicted:\n",
        "  [' Ms. Wertheimer ', 'FEMALE']                    ['Ms. Wertheimer', 'FEMALE']\n",
        "  [' Ms. Taylor ', 'FEMALE,']                       ['Ms. Taylor', 'FEMALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Siegel ', 'MALE_NO_ID']                        \n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Dick Cavett ', 'MALE']                         ['Dick Cavett', 'MALE']\n",
        "  [\" Siegel's \", 'MALE_NO_ID']                      \n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Terry Gross ', 'FEMALE']                       ['Terry Gross', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Ms. Gross ', 'FEMALE,']                        ['Ms. Gross', 'FEMALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Ms. Gross ', 'FEMALE']                         ['Ms. Gross', 'FEMALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Eddie Miller ', 'MALE,']                       ['Eddie Miller', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [\" Ms. Gross' \", 'FEMALE']                        ['Ms. Gross', 'FEMALE']\n",
        "                                                    ['Man', 'MALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Miller ', 'MALE']                              ['Ms. Gross', 'FEMALE']\n",
        "  [' Ms. Gross ', 'FEMALE']                         \n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Ms. Gross ', 'FEMALE']                         ['Ms. Gross', 'FEMALE']\n",
        "  [' Miller ', 'MALE_NO_ID']                        \n",
        "Actual:                                           Predicted:\n",
        "  [' Ms. Gross ', 'FEMALE']                         ['Ms. Gross', 'FEMALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [\" Dick Clark's \", 'MALE']                        ['Dick Clark', 'MALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Ms. Gross ', 'FEMALE']                         ['Ms. Gross', 'FEMALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [\" John Perry Barlow's \", 'MALE']                 ['John Perry Barlow', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Mike Godwin ', 'MALE,']                        ['Mike Godwin', 'MALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Sidney Blumenthal ', 'MALE,']                  ['Sidney Blumenthal', 'MALE']\n",
        "  [' Matt Drudge, ', 'MALE']                        ['Matt Drudge', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Drudge ', 'MALE_NO_ID']                        ['Angeles', 'FEMALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Cindy Cohn, ', 'FEMALE']                       ['Cindy Cohn', 'FEMALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Ms. Cohn, ', 'FEMALE']                         ['Ms. Cohn', 'FEMALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Ms. Cohn ', 'FEMALE']                          ['Ms. Cohn', 'FEMALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Judge Stewart Dalzell ', 'MALE,']              ['Stewart Dalzell', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Jack N. Berkman ', 'MALE,']                    ['Jack N', 'MALE']\n",
        "  [' Lillian R. Berkman ', 'FEMALE']                ['Lillian R', 'FEMALE']\n",
        "  [' Jonathan Zittrain ', 'MALE']                   ['Jonathan Zittrain', 'MALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Prof. Charles Nesson ', 'MALE,']               ['Charles Nesson', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Lawrence Lessig ', 'MALE,']                    ['Lawrence Lessig', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' James Boyle ', 'MALE']                         ['James Boyle', 'MALE']\n",
        "  [' Robert Mergess ', 'MALE,']                     ['Robert Mergess', 'MALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Jack Balkin ', 'MALE,']                        ['Jack Balkin', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Pam Samuelson ', 'FEMALE,']                    ['Pam Samuelson', 'FEMALE']\n",
        "  [' Mergess ', 'MALE_NO_ID']                       \n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Ms. Samuelson ', 'FEMALE,']                    ['Ms. Samuelson', 'FEMALE']\n",
        "                                                    ['Clinton', 'MALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Ms. Samuelson ', 'FEMALE']                     ['Ms. Samuelson', 'FEMALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Ms. Samuelson ', 'FEMALE']                     ['Ms. Samuelson', 'FEMALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Michael Froomkin ', 'MALE']                    ['Michael Froomkin', 'MALE']\n",
        "  [' Dan Burk ', 'MALE']                            ['Dan Burk', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' David Post ', 'MALE,']                         ['David Post', 'MALE']\n",
        "                                                    ['Temple University Law School', 'FEMALE']\n",
        "Actual:                                           Predicted:\n",
        "  [' Frank Easterbrook ', 'MALE']                   ['Frank Easterbrook', 'MALE']\n",
        "Actual:                                           Predicted:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  [' Brian Dally ', 'MALE,']                        ['Brian Dally', 'MALE']\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This data set really doesn't do much in terms of exploring the space of possible names so any performance metrics based on this are extremely suspect. That said, for all tags:\n",
      "\n",
      "- Exact matches:   46\n",
      "- False positives: 3\n",
      "- False negatives: 15 (12 of these were NO_ID)\n",
      "- Partial matches: 3\n",
      "\n",
      "Our terminology:\n",
      "\n",
      "- 'exact match' = name had correct boundaries (titles excepted) and gender correctly identified\n",
      "- 'false positive' = non-name extracted as a name\n",
      "- 'false negative' = actual name overlooked\n",
      "- 'partial match' = name boundaries partially incorrect or gender misidentified\n",
      "\n",
      "The name identified did not fare particularly well in general but in situations with gender flags present it did. We count partial matches as false negatives."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f1_score = 2 * 46.0 / (2 * 46 + 3 + 6)\n",
      "print f1_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.910891089109\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, the statistical strength of this test is approximately nil since the same small set of names was used repeatedly. Given that I'm not going to continue to construct a gender-tagged data set, we can still evaluate the theoretical performance of the gender classifier under some assumptions. Namely, we require that the data used to build the namebank is relevant to the population in question.\n",
      "\n",
      "If that assumption holds (err...) then we can expect the following performance. Note that the namebank data only covers the most prevalent 90% of names for each gender. For unseen names we would guess \"female\" every time, yielding 51% accuracy on the remainder. This evaluation is modulo the performance of the NER engine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshold = 0.999999999\n",
      "x, y = build_namebank()\n",
      "\n",
      "slam_dunks = [0, 0]\n",
      "for key in x.keys():\n",
      "    if abs(x[key] - 0.5) < threshold/2:\n",
      "        slam_dunks[1] += 1\n",
      "        \n",
      "    if abs(x[key]-0.5) > threshold/2:\n",
      "        slam_dunks[0] += 1\n",
      "\n",
      "print \"Out of the names provided in the data, \" + str(round(100 * float(slam_dunks[0]) / sum(slam_dunks))) + \"% resolve with no ambiguity.\"\n",
      "\n",
      "guesses = [0,0]\n",
      "for key in y.keys():\n",
      "    guesses[0] += max(y[key])\n",
      "    guesses[1] += min(y[key])\n",
      "\n",
      "print \"Overall, the best guess would be correct in \" + str(0.9 * round(100* guesses[0] / sum(guesses)) + 5.1) + \"% of cases.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Out of the names provided in the data, 94.0% resolve with no ambiguity.\n",
        "Overall, the best guess would be correct in 94.2% of cases.\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Current limitations:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- This implementation relies on my lame NER tool which needs help from punctuation, capitalization etc. This can be improved by plugging in a better NER.\n",
      "- Gender identifier can't currently handle extremely rare names. This falls under the category of disambiguation, below."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Resolving ambiguity:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To build a more advanced system which could identify gender with more precision, I would bootstrap from something like the current method. While this method may not be particularly accurate, there are situations in which it is almost guaranteed to be perfect (again, this is modulo the performance of the NER). If there are highly skewed names (\"Jennifer\" or \"Michael\") or gender-specific titles (\"Ms.\") then this method is a slam dunk.\n",
      "\n",
      "To turn that into a good classifier, we can take a large corpus of text (from an NER benchmark for instance, since we'll be able to verify the locations of persons within the text) and filter by sentences with references that only come from one of these slam dunk cases. Following that filtration, I would replace these names with completely random names of either gender. This converts our collection of sentences in which we know ground truth into a collection in which every name has manufactured ambiguity.\n",
      "\n",
      "However, because we still know ground truth we can train a supervised classifier on this data (I'm partial to neural nets). Because named references which are ambiguous can only be resolved by looking at context, this model will learn to resolve these cases using that information. It will learn to find context clues that can be used to determine gender. I would certainly include part of speech information as a feature as well.\n",
      "\n",
      "There are definitely other methods but this one appeals to me since it feels like alchemy. It's always more satisfying to do something clever than something like statistical analysis of letter distributions for male vs female."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}